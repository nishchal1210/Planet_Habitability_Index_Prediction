{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bba2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aaaaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=pd.read_csv('exoplanet_dataset.csv') \n",
    "dt.isnull().sum() \n",
    "dt2=dt[['P_TEMP_EQUIL','P_TEMP_SURF']] \n",
    "null_col1_rows = dt2[dt2['P_TEMP_EQUIL'].isna()]\n",
    "non_null_col1_dt = dt2.dropna(subset=['P_TEMP_EQUIL'])\n",
    "train_data = non_null_col1_dt[~non_null_col1_dt['P_TEMP_SURF'].isna()]\n",
    "test_data = non_null_col1_dt[non_null_col1_dt['P_TEMP_SURF'].isna()]\n",
    "x = train_data[['P_TEMP_EQUIL']]\n",
    "y = train_data['P_TEMP_SURF']\n",
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.01, max_depth=7, random_state=42)\n",
    "model.fit(x, y)\n",
    "x_test = test_data[['P_TEMP_EQUIL']]\n",
    "test_data['P_TEMP_SURF'] = model.predict(x_test)\n",
    "filled_data = pd.concat([train_data, test_data]).sort_index()\n",
    "final_dt = pd.concat([filled_data, null_col1_rows]).sort_index()\n",
    "dt['P_TEMP_EQUIL']=final_dt['P_TEMP_EQUIL']\n",
    "dt['P_TEMP_SURF']=final_dt['P_TEMP_SURF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13064e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.0903 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 2/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0154 - mae: 0.0775 - val_loss: 0.0174 - val_mae: 0.0741\n",
      "Epoch 3/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0749 - val_loss: 0.0125 - val_mae: 0.0679\n",
      "Epoch 4/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0661 - val_loss: 0.0109 - val_mae: 0.0613\n",
      "Epoch 5/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0670 - val_loss: 0.0109 - val_mae: 0.0623\n",
      "Epoch 6/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0633 - val_loss: 0.0107 - val_mae: 0.0604\n",
      "Epoch 7/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0591 - val_loss: 0.0119 - val_mae: 0.0611\n",
      "Epoch 8/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0599 - val_loss: 0.0112 - val_mae: 0.0565\n",
      "Epoch 9/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0573 - val_loss: 0.0121 - val_mae: 0.0683\n",
      "Epoch 10/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0078 - mae: 0.0552 - val_loss: 0.0124 - val_mae: 0.0582\n",
      "Epoch 11/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0079 - mae: 0.0547 - val_loss: 0.0115 - val_mae: 0.0746\n",
      "Epoch 12/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0073 - mae: 0.0518 - val_loss: 0.0093 - val_mae: 0.0605\n",
      "Epoch 13/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0076 - mae: 0.0537 - val_loss: 0.0113 - val_mae: 0.0518\n",
      "Epoch 14/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0079 - mae: 0.0538 - val_loss: 0.0161 - val_mae: 0.0593\n",
      "Epoch 15/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0063 - mae: 0.0500 - val_loss: 0.0112 - val_mae: 0.0504\n",
      "Epoch 16/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0069 - mae: 0.0495 - val_loss: 0.0475 - val_mae: 0.0810\n",
      "Epoch 17/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0076 - mae: 0.0511 - val_loss: 0.0097 - val_mae: 0.0596\n",
      "Epoch 18/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0067 - mae: 0.0495 - val_loss: 0.0091 - val_mae: 0.0490\n",
      "Epoch 19/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0072 - mae: 0.0505 - val_loss: 0.0098 - val_mae: 0.0503\n",
      "Epoch 20/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0057 - mae: 0.0464 - val_loss: 0.0072 - val_mae: 0.0481\n",
      "Epoch 21/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0468 - val_loss: 0.0109 - val_mae: 0.0453\n",
      "Epoch 22/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0052 - mae: 0.0433 - val_loss: 0.0101 - val_mae: 0.0487\n",
      "Epoch 23/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0042 - mae: 0.0402 - val_loss: 0.0075 - val_mae: 0.0377\n",
      "Epoch 24/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0055 - mae: 0.0437 - val_loss: 0.0064 - val_mae: 0.0408\n",
      "Epoch 25/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0063 - mae: 0.0467 - val_loss: 0.0078 - val_mae: 0.0491\n",
      "Epoch 26/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0423 - val_loss: 0.0107 - val_mae: 0.0441\n",
      "Epoch 27/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0051 - mae: 0.0418 - val_loss: 0.0082 - val_mae: 0.0478\n",
      "Epoch 28/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0049 - mae: 0.0425 - val_loss: 0.0073 - val_mae: 0.0397\n",
      "Epoch 29/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0041 - mae: 0.0374 - val_loss: 0.0080 - val_mae: 0.0404\n",
      "Epoch 30/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0041 - mae: 0.0366 - val_loss: 0.0091 - val_mae: 0.0429\n",
      "Epoch 31/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0408 - val_loss: 0.0065 - val_mae: 0.0386\n",
      "Epoch 32/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0404 - val_loss: 0.0070 - val_mae: 0.0358\n",
      "Epoch 33/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0357 - val_loss: 0.0070 - val_mae: 0.0347\n",
      "Epoch 34/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0043 - mae: 0.0370 - val_loss: 0.0057 - val_mae: 0.0454\n",
      "Epoch 35/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0342 - val_loss: 0.0073 - val_mae: 0.0501\n",
      "Epoch 36/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0356 - val_loss: 0.0032 - val_mae: 0.0311\n",
      "Epoch 37/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0036 - mae: 0.0347 - val_loss: 0.0043 - val_mae: 0.0285\n",
      "Epoch 38/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0315 - val_loss: 0.0049 - val_mae: 0.0300\n",
      "Epoch 39/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0303 - val_loss: 0.0043 - val_mae: 0.0333\n",
      "Epoch 40/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0315 - val_loss: 0.0083 - val_mae: 0.0374\n",
      "Epoch 41/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0304 - val_loss: 0.0061 - val_mae: 0.0353\n",
      "Epoch 42/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0313 - val_loss: 0.0052 - val_mae: 0.0394\n",
      "Epoch 43/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0354 - val_loss: 0.0056 - val_mae: 0.0282\n",
      "Epoch 44/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0309 - val_loss: 0.0057 - val_mae: 0.0298\n",
      "Epoch 45/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0332 - val_loss: 0.0073 - val_mae: 0.0236\n",
      "Epoch 46/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0268 - val_loss: 0.0035 - val_mae: 0.0324\n",
      "Epoch 47/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0042 - mae: 0.0369 - val_loss: 0.0047 - val_mae: 0.0247\n",
      "Epoch 48/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0275 - val_loss: 0.0099 - val_mae: 0.0260\n",
      "Epoch 49/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0299 - val_loss: 0.0073 - val_mae: 0.0272\n",
      "Epoch 50/50\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0041 - mae: 0.0363 - val_loss: 0.0159 - val_mae: 0.0435\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "dt=dt.drop(['P_INCLINATION','P_OMEGA','S_NAME_HD','S_NAME_HIP','S_TYPE'],axis=1) \n",
    "columns_to_predict_eccentricity = [\n",
    "    \"P_MASS\",\n",
    "    \"P_PERIASTRON\",\n",
    "    \"P_APASTRON\",\n",
    "    \"P_DISTANCE_EFF\",\n",
    "    \"S_TIDAL_LOCK\",\n",
    "    \"P_HILL_SPHERE\" ,\n",
    "    \"P_ECCENTRICITY\"\n",
    "]\n",
    "dt2=dt[columns_to_predict_eccentricity]\n",
    "columns = [\n",
    "    \"P_MASS\",\n",
    "    \"P_PERIASTRON\",\n",
    "    \"P_APASTRON\",\n",
    "    \"P_DISTANCE_EFF\",\n",
    "    \"S_TIDAL_LOCK\",\n",
    "    \"P_HILL_SPHERE\"\n",
    "] \n",
    "dt_with_nulls = dt2[dt2[columns].isnull().any(axis=1)]\n",
    "dt_no_nulls = dt2.dropna(subset=columns)\n",
    "train_data = dt_no_nulls.dropna(subset=['P_ECCENTRICITY'])\n",
    "x = train_data[columns]\n",
    "y = train_data['P_ECCENTRICITY']\n",
    "x_predict = dt_no_nulls[dt_no_nulls['P_ECCENTRICITY'].isnull()][columns]\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x_predict = scaler.transform(x_predict)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train ,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    verbose=1\n",
    ") \n",
    "predicted_values = model.predict(x_predict)\n",
    "dt_no_nulls.loc[dt_no_nulls['P_ECCENTRICITY'].isnull(), 'P_ECCENTRICITY'] = predicted_values\n",
    "dt_final = pd.concat([dt_no_nulls, dt_with_nulls]).sort_index() \n",
    "dt['P_ECCENTRICITY']=dt_final['P_ECCENTRICITY']\n",
    "dt=dt[['P_NAME','P_MASS','P_RADIUS','P_PERIOD','P_SEMI_MAJOR_AXIS','P_ECCENTRICITY','S_DISTANCE','S_TEMPERATURE','S_MASS','S_RADIUS','P_ESCAPE','P_POTENTIAL','P_GRAVITY','P_DENSITY','P_HILL_SPHERE','P_DISTANCE','P_PERIASTRON','P_APASTRON','P_DISTANCE_EFF','P_FLUX','P_TEMP_EQUIL','P_TEMP_SURF','P_TYPE','S_TYPE_TEMP','S_LUMINOSITY','S_SNOW_LINE','S_ABIO_ZONE','S_TIDAL_LOCK','P_HABZONE_OPT','P_HABZONE_CON','P_TYPE_TEMP','P_HABITABLE','S_LOG_G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22fb9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = dt.select_dtypes(include=['float64', 'int64']).columns\n",
    "data = dt[numerical_features]\n",
    "\n",
    "\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "k = 5\n",
    "imputer = KNNImputer(n_neighbors=k, weights='distance')\n",
    "\n",
    "\n",
    "scaled_data_imputed = imputer.fit_transform(scaled_data)\n",
    "\n",
    "\n",
    "kd_tree = NearestNeighbors(n_neighbors=k, algorithm='kd_tree')\n",
    "kd_tree.fit(scaled_data_imputed)\n",
    "\n",
    "\n",
    "imputed_data_rescaled = scaler.inverse_transform(scaled_data_imputed)\n",
    "\n",
    "\n",
    "dt[numerical_features] = imputed_data_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3276c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_type_features = ['P_TEMP_EQUIL', 'P_FLUX', 'P_RADIUS', 'P_GRAVITY']\n",
    "s_type_features = ['S_TEMPERATURE', 'S_LUMINOSITY', 'S_RADIUS', 'S_MASS']\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "dt[p_type_features] = imputer.fit_transform(dt[p_type_features])\n",
    "dt[s_type_features] = imputer.fit_transform(dt[s_type_features])\n",
    "\n",
    "\n",
    "label_encoder_p = LabelEncoder()\n",
    "label_encoder_s = LabelEncoder()\n",
    "\n",
    "dt['P_TYPE_TEMP_ENC'] = label_encoder_p.fit_transform(dt['P_TYPE_TEMP'].fillna('Unknown'))\n",
    "dt['S_TYPE_TEMP_ENC'] = label_encoder_s.fit_transform(dt['S_TYPE_TEMP'].fillna('Unknown'))\n",
    "\n",
    "\n",
    "def impute_with_model(dt, target_col, features, label_encoder):\n",
    "\n",
    "    train_data = dt[dt[target_col] != 'Unknown']\n",
    "    predict_data = dt[dt[target_col] == 'Unknown']\n",
    "\n",
    "    x_train = train_data[features]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    if predict_data.empty:\n",
    "        return dt\n",
    "\n",
    "    x_predict = predict_data[features]\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    predicted_values = clf.predict(x_predict)\n",
    "\n",
    "\n",
    "    dt.loc[dt[target_col] == 'Unknown', target_col] = predicted_values\n",
    "    return dt\n",
    "\n",
    "\n",
    "dt = impute_with_model(dt, 'P_TYPE_TEMP_ENC', p_type_features, label_encoder_p)\n",
    "\n",
    "\n",
    "dt = impute_with_model(dt, 'S_TYPE_TEMP_ENC', s_type_features, label_encoder_s)\n",
    "\n",
    "\n",
    "dt['P_TYPE_TEMP'] = label_encoder_p.inverse_transform(dt['P_TYPE_TEMP_ENC'])\n",
    "dt['S_TYPE_TEMP'] = label_encoder_s.inverse_transform(dt['S_TYPE_TEMP_ENC'])\n",
    "\n",
    "\n",
    "dt.drop(columns=['P_TYPE_TEMP_ENC', 'S_TYPE_TEMP_ENC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1622b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_type_features = ['P_TEMP_EQUIL', 'P_FLUX', 'P_RADIUS', 'P_GRAVITY']\n",
    "\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "dt[p_type_features] = imputer.fit_transform(dt[p_type_features])\n",
    "\n",
    "\n",
    "\n",
    "label_encoder_p = LabelEncoder()\n",
    "\n",
    "\n",
    "dt['P_TYPE_TEMP_ENC'] = label_encoder_p.fit_transform(dt['P_TYPE'].fillna('Unknown'))\n",
    "\n",
    "\n",
    "def impute_with_model(dt, target_col, features, label_encoder):\n",
    "\n",
    "    train_data = dt[dt[target_col] != 'Unknown']\n",
    "    predict_data = dt[dt[target_col] == 'Unknown']\n",
    "\n",
    "    x_train = train_data[features]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    if predict_data.empty:\n",
    "        return dt\n",
    "\n",
    "    x_predict = predict_data[features]\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    predicted_values = clf.predict(x_predict)\n",
    "\n",
    "\n",
    "    dt.loc[dt[target_col] == 'Unknown', target_col] = predicted_values\n",
    "    return dt\n",
    "\n",
    "\n",
    "dt = impute_with_model(dt, 'P_TYPE_TEMP_ENC', p_type_features, label_encoder_p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dt['P_TYPE'] = label_encoder_p.inverse_transform(dt['P_TYPE_TEMP_ENC'])\n",
    "\n",
    "\n",
    "\n",
    "dt.drop(columns=['P_TYPE_TEMP_ENC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362c57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_atmospheric_retention(row):\n",
    "    # Earth's reference values\n",
    "    earth_escape = 11.2  # km/s\n",
    "    earth_temp = 288.0   # K\n",
    "\n",
    "    v_escape = row['P_ESCAPE']\n",
    "    T_surf = row['P_TEMP_SURF']\n",
    "\n",
    "    # If data is missing or T_surf==0, return NaN\n",
    "    if np.isnan(v_escape) or np.isnan(T_surf) or T_surf == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Compute the ratio; for Earth, ratio_AR = (11.2/11.2)*(288/288) = 1.\n",
    "    ratio_AR = (v_escape / earth_escape) * (earth_temp / T_surf)\n",
    "\n",
    "    # Use piecewise linear mapping: if ratio >= 1 then score = 100, else 100 * ratio.\n",
    "    AR = 100 if ratio_AR >= 1 else 100 * ratio_AR\n",
    "    return AR\n",
    "\n",
    "# Revised formula for Long-Term Stability:\n",
    "def compute_long_term_stability(row):\n",
    "    # Earth's reference values\n",
    "    earth_lum = 1.0      # solar luminosity\n",
    "    earth_sma = 1.0      # AU\n",
    "\n",
    "    e = row['P_ECCENTRICITY']\n",
    "    S_lum = row['S_LUMINOSITY']\n",
    "    sma = row['P_SEMI_MAJOR_AXIS']\n",
    "\n",
    "    # If data is missing or invalid, return NaN\n",
    "    if np.isnan(e) or np.isnan(S_lum) or np.isnan(sma) or S_lum == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Compute the ratio; for Earth: (1 - 0) * (1/1) * (1/1) = 1.\n",
    "    ratio_LTS = (1 - e) * (earth_lum / S_lum) * (sma / earth_sma)\n",
    "\n",
    "    # Piecewise mapping: if ratio >= 1 then score = 100, else 100 * ratio.\n",
    "    LTS = 100 if ratio_LTS >= 1 else 100 * ratio_LTS\n",
    "    return LTS\n",
    "\n",
    "# Apply these functions to create new columns:\n",
    "dt['Atmospheric_Retention'] = dt.apply(compute_atmospheric_retention, axis=1)\n",
    "dt['Long_Term_Stability'] = dt.apply(compute_long_term_stability, axis=1) \n",
    "def compute_esi(row):\n",
    "    # Reference Earth values:\n",
    "    earth_radius = 1.0    # Earth radii (assuming normalized units, or set actual units if available)\n",
    "    earth_density = 5.51  # g/cm³ (Earth's average density)\n",
    "    earth_escape = 11.2   # km/s (Earth's escape velocity)\n",
    "    earth_temp = 288.0    # K (Earth's average surface temperature)\n",
    "\n",
    "    # Weights for each parameter (tunable based on literature; example values)\n",
    "    w_radius = 0.57\n",
    "    w_density = 1.07\n",
    "    w_escape = 0.70\n",
    "    w_temp = 5.58\n",
    "\n",
    "    # Helper function to compute similarity for one parameter:\n",
    "    def esi_component(x, x_earth, w):\n",
    "        # Avoid division by zero; assume if x and x_earth are both 0, similarity is 1.\n",
    "        if (x + x_earth) == 0:\n",
    "            return 1.0\n",
    "        return (1 - abs(x - x_earth) / (x + x_earth)) ** w\n",
    "\n",
    "    # Compute each component:\n",
    "    esi_radius = esi_component(row['P_RADIUS'], earth_radius, w_radius)\n",
    "    esi_density = esi_component(row['P_DENSITY'], earth_density, w_density)\n",
    "    esi_escape = esi_component(row['P_ESCAPE'], earth_escape, w_escape)\n",
    "    esi_temp = esi_component(row['P_TEMP_SURF'], earth_temp, w_temp)\n",
    "\n",
    "    # Compute interior and surface components:\n",
    "    esi_interior = np.sqrt(esi_radius * esi_density)\n",
    "    esi_surface = np.sqrt(esi_escape * esi_temp)\n",
    "\n",
    "    # Overall ESI is the geometric mean of the interior and surface components:\n",
    "    esi = np.sqrt(esi_interior * esi_surface)\n",
    "    # Optionally, you can scale the overall ESI to a 0-100 scale:\n",
    "    # For instance: ESI_percent = 100 * esi\n",
    "    return 100 * esi\n",
    "dt['ESI']=dt.apply(compute_esi,axis=1)  \n",
    "dt.to_csv(\"processed_dataset.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
